<div align="center">

# üöú Gado-Scraper

**Pipeline automatizada para monitoramento di√°rio de cota√ß√µes pecu√°rias**

[![Python](https://img.shields.io/badge/Python-3.10%2B-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-CI%2FCD-2088FF?style=for-the-badge&logo=githubactions&logoColor=white)](https://github.com/features/actions)
[![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup4-Scraping-4B8BBE?style=for-the-badge)](https://pypi.org/project/beautifulsoup4/)
[![Status](https://img.shields.io/badge/Pipeline-Ativa%20Diariamente-brightgreen?style=for-the-badge)](https://github.com/Dom1ng0s/Gado-Scraper/actions)

> Pipeline de dados que coleta automaticamente as cota√ß√µes de **boi gordo** e **novilha** todos os dias ‚Äî sem servidores, sem custos, sem interven√ß√£o manual. O pr√≥prio GitHub vira a infraestrutura.

</div>

---

## üí° A Ideia por Tr√°s do Projeto

Pecuaristas tomam decis√µes de compra e venda baseadas nas cota√ß√µes do dia. O problema: essas informa√ß√µes est√£o espalhadas em sites de dif√≠cil automa√ß√£o e n√£o existem APIs p√∫blicas confi√°veis para o setor.

O Gado-Scraper resolve isso com uma abordagem elegante e de custo zero:

- **GitHub Actions** age como um cron job na nuvem, rodando os scrapers todo dia
- **O pr√≥prio reposit√≥rio** funciona como banco de dados hist√≥rico ‚Äî cada commit √© um snapshot do pre√ßo naquele dia
- **Sem infraestrutura pr√≥pria** ‚Äî sem servidor, sem banco de dados, sem custos de cloud

---

## ‚öôÔ∏è Como a Pipeline Funciona

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              GitHub Actions (todo dia)               ‚îÇ
‚îÇ                                                      ‚îÇ
‚îÇ  1. Checkout do reposit√≥rio                          ‚îÇ
‚îÇ  2. pip install -r requirements.txt                  ‚îÇ
‚îÇ  3. python scraper_boi.py     ‚îÄ‚îÄ‚ñ∫ cotacoes_boi_hoje.json     ‚îÇ
‚îÇ  4. python scraper_novilha.py ‚îÄ‚îÄ‚ñ∫ cotacoes_novilha_hoje.json ‚îÇ
‚îÇ  5. git commit + git push (atualiza o reposit√≥rio)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

O arquivo `.github/workflows/` cont√©m o workflow agendado com **cron expression**, que dispara automaticamente em hor√°rio de mercado.

---

## üìä Formato dos Dados Coletados

Os scrapers exportam os dados em JSON estruturado, prontos para consumo por qualquer sistema:

**`cotacoes_boi_hoje.json`**
```json
[
  {
    "data": "2026-02-24",
    "categoria": "Boi Gordo",
    "preco_arroba": "R$ 320,50",
    "regiao": "S√£o Paulo",
    "fonte": "..."
  }
]
```

**`cotacoes_novilha_hoje.json`**
```json
[
  {
    "data": "2026-02-24",
    "categoria": "Novilha",
    "preco_arroba": "R$ 290,00",
    "regiao": "Mato Grosso",
    "fonte": "..."
  }
]
```

> üíæ **O hist√≥rico de pre√ßos est√° preservado no git log** ‚Äî cada commit di√°rio √© um ponto de dado para an√°lise de s√©ries temporais.

---

## üõ†Ô∏è Stack Tecnol√≥gica

| Responsabilidade | Tecnologia |
|---|---|
| **Linguagem** | Python 3.10+ |
| **Scraping** | Requests + BeautifulSoup4 |
| **Automa√ß√£o / CI** | GitHub Actions (Cron) |
| **Armazenamento** | JSON no pr√≥prio reposit√≥rio |
| **Versionamento hist√≥rico** | Git (cada commit = snapshot di√°rio) |

---

## üóÇÔ∏è Estrutura do Projeto

```
Gado-Scraper/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ daily_scrape.yml      # Cron job: roda todo dia automaticamente
‚îú‚îÄ‚îÄ scraper_boi.py                # Coleta cota√ß√µes de boi gordo
‚îú‚îÄ‚îÄ scraper_novilha.py            # Coleta cota√ß√µes de novilha
‚îú‚îÄ‚îÄ cotacoes_boi_hoje.json        # Dados mais recentes (atualizado pela pipeline)
‚îú‚îÄ‚îÄ cotacoes_novilha_hoje.json    # Dados mais recentes (atualizado pela pipeline)
‚îî‚îÄ‚îÄ requirements.txt
```

---

## üöÄ Como Rodar Localmente

```bash
# 1. Clone o reposit√≥rio
git clone https://github.com/Dom1ng0s/Gado-Scraper.git
cd Gado-Scraper

# 2. Instale as depend√™ncias
pip install -r requirements.txt

# 3. Execute os scrapers manualmente
python scraper_boi.py
python scraper_novilha.py
```

Os arquivos JSON ser√£o gerados/atualizados na raiz do projeto.

---

## üîß Como Fazer o Fork e Usar no Seu Reposit√≥rio

A pipeline roda automaticamente em qualquer fork. Basta:

1. Fazer o fork do reposit√≥rio
2. Ir em **Settings ‚Üí Actions ‚Üí General** e habilitar os workflows
3. O GitHub Actions vai rodar o scraper automaticamente todo dia

> Nenhuma configura√ß√£o adicional necess√°ria ‚Äî sem vari√°veis de ambiente, sem tokens de API.

---

## üó∫Ô∏è Pr√≥ximas Evolu√ß√µes

- [ ] Notifica√ß√£o via Telegram quando o pre√ßo ultrapassar um threshold
- [ ] Dashboard com hist√≥rico de varia√ß√µes (Streamlit ou Grafana)
- [X] Integra√ß√£o direta com o [sistema_gado](https://github.com/Dom1ng0s/sistema_gado) para alimentar cota√ß√µes em tempo real
- [ ] Exporta√ß√£o para CSV para an√°lise em Excel/Pandas

---

## üë§ Autor

**Davi Domingos de Oliveira**
Estudante de Ci√™ncia da Computa√ß√£o ‚Äî UFAL | Backend Developer

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=flat&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/davidomingosdeoliveira/)
[![GitHub](https://img.shields.io/badge/GitHub-181717?style=flat&logo=github&logoColor=white)](https://github.com/Dom1ng0s)
[![Email](https://img.shields.io/badge/Email-D14836?style=flat&logo=gmail&logoColor=white)](mailto:odomingosdavi@gmail.com)
