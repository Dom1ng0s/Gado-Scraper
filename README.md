# ğŸ‚ Gado-Scraper: AutomaÃ§Ã£o de CotaÃ§Ãµes PecuÃ¡rias

> **Pipeline automatizada para coleta e monitoramento diÃ¡rio de preÃ§os do boi gordo e novilha.**

Este projeto utiliza Web Scraping para extrair cotaÃ§Ãµes atualizadas do setor pecuÃ¡rio e armazena os dados em formato JSON. O diferencial Ã© a automaÃ§Ã£o total via **GitHub Actions**, que executa o script diariamente, garantindo dados sempre frescos sem intervenÃ§Ã£o manual.

## ğŸš€ Funcionalidades

- **ğŸ Scraping Inteligente:** Scripts em Python especializados para extrair dados de fontes do setor.
- **ğŸ¤– AutomaÃ§Ã£o Total:** Workflow do GitHub Actions configurado para rodar todos os dias.
- **ğŸ“Š Dados Estruturados:** ExportaÃ§Ã£o automÃ¡tica para arquivos `.json` (`cotacoes_boi_hoje.json` e `cotacoes_novilha_hoje.json`).
- **ğŸ”„ HistÃ³rico de Commits:** O prÃ³prio repositÃ³rio serve como um log histÃ³rico das variaÃ§Ãµes de preÃ§o.

## ğŸ› ï¸ Tecnologias Utilizadas

- **Linguagem:** Python 3.x
- **Bibliotecas:** `requests`, `beautifulsoup4`
- **CI/CD:** GitHub Actions (Agendamento via Cron)

## ğŸ“‚ Estrutura de Dados

Os dados coletados seguem o formato:
```json
{
  "data": "2026-01-15",
  "preco": "R$ XXX,XX",
  "regiao": "..."
}
```

## âš™ï¸ Como Funciona a AutomaÃ§Ã£o

O arquivo `.github/workflows/atualizacao_diaria.yml` estÃ¡ configurado para:
1. Instalar o ambiente Python.
2. Executar os scripts `scraper_boi.py` e `scraper_novilha.py`.
3. Realizar o `git commit` e `push` dos arquivos JSON atualizados de volta para o repositÃ³rio.

## ğŸ’» Como Executar Localmente

1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/Dom1ng0s/Gado-Scraper.git
   ```
2. Instale as dependÃªncias:
   ```bash
   pip install -r requirements.txt
   ```
3. Execute o scraper:
   ```bash
   python scraper_boi.py
   ```

---
Desenvolvido por [Davi Domingos](https://github.com/Dom1ng0s)
